{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FizzBuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "FizzBuzz 函數func(x) x為整數!\n",
    "x整除3 輸出'Fizz'\n",
    "x整除5 輸出'Buzz'\n",
    "同時整除3,5(整除15)輸出'FizzBuzz'\n",
    "以上條件都不符合 輸出原數x\n",
    "'''\n",
    "def FizzBuzz(x):\n",
    "    word = ''\n",
    "    if x % 3 == 0:\n",
    "        word += 'Fizz'\n",
    "    if x % 5 == 0:\n",
    "        word += 'Buzz'\n",
    "    if word == '':\n",
    "        word += str(x)\n",
    "    return word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FizzBuzz 範例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "Fizz\n",
      "4\n",
      "Buzz\n",
      "Fizz\n",
      "7\n",
      "8\n",
      "Fizz\n",
      "Buzz\n",
      "11\n",
      "Fizz\n",
      "13\n",
      "14\n",
      "FizzBuzz\n",
      "16\n",
      "17\n",
      "Fizz\n",
      "19\n",
      "Buzz\n",
      "Fizz\n",
      "22\n",
      "23\n",
      "Fizz\n",
      "Buzz\n",
      "26\n",
      "Fizz\n",
      "28\n",
      "29\n",
      "FizzBuzz\n"
     ]
    }
   ],
   "source": [
    "for n_ in range(1,31):\n",
    "    print(FizzBuzz(n_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "產生labels (one hot) x = 1~1000\n",
    "func(x) = 'x' :[1, 0, 0, 0]\n",
    "func(x) = 'Fizz' :[0, 1, 0, 0]\n",
    "func(x) = 'Buzz' :[0, 0, 1, 0]\n",
    "func(x) = 'FizzBuzz' :[0, 0, 0, 1]\n",
    "'''\n",
    "l = np.array([])\n",
    "for i in range(1, 1001):\n",
    "    a = 0\n",
    "    if i % 3 == 0:\n",
    "        a+=1\n",
    "    if i % 5 == 0:\n",
    "        a+=2\n",
    "    l = np.append(l, a)\n",
    "# 數列轉成 labels\n",
    "l = np.vstack((l==0, l==1, l==2, l==3)).T.astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels範例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "產生train data\n",
    "1~1000 用二進位輸出 共十位數(10 dim vector)\n",
    "data shape = [1000, 10]\n",
    "'''\n",
    "# b 1~1000 二進位數列\n",
    "b = []\n",
    "for i in range(1, 1001):\n",
    "    add_zero = 10 - len(bin(i)[2:])\n",
    "    b.append(('0' * add_zero) + bin(i)[2:])\n",
    "# bn:data\n",
    "bn = np.zeros([1000, 10])\n",
    "for n_ in range(1000):\n",
    "    for i_ in range(10):\n",
    "        if b[n_][i_] == '1':\n",
    "            bn[n_, i_] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二進位範例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 1., 1., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 0., 1., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 1., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 1., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 1., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 1., 1., 1., 1.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 0., 1., 1.],\n",
       "       [0., 0., 0., 0., 0., 1., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn[0:20] #0~10 二進位"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 設定 Train_data, Test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = bn[100:1000], bn[0:100]\n",
    "t_train, t_test = l[100:1000], l[0:100]\n",
    "n_num = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 設定兩層框架"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = tf.placeholder(tf.float32, [None, 10], name='x_input')\n",
    "ts = tf.placeholder(tf.float32, [None, 4], name='t_input')\n",
    "keep_prob = tf.placeholder(tf.float32) # dropout 保持率\n",
    "\n",
    "W1 = tf.Variable(name='W1', initial_value=tf.random_normal(shape=[10, n_num], stddev=(2/n_num)**0.5, seed=47))\n",
    "b1 = tf.Variable(name='b1', initial_value=tf.random_normal(shape=[n_num], stddev=(2/n_num)**0.5, seed=47))\n",
    "W2 = tf.Variable(name='W2', initial_value=tf.random_normal(shape=[n_num, 4], stddev=(2/4)**0.5, seed=47))\n",
    "b2 = tf.Variable(name='b2', initial_value=tf.random_normal(shape=[4], stddev=(2/4)**0.5, seed=47))\n",
    "\n",
    "W1x_plus_b1 = tf.add(tf.matmul(xs, W1), b1)\n",
    "z1 = tf.nn.relu(W1x_plus_b1)\n",
    "z2 = tf.nn.dropout(z1, keep_prob=keep_prob)\n",
    "W2z1_plus_b2 = tf.add(tf.matmul(z2, W2), b2)\n",
    "y = tf.nn.softmax(W2z1_plus_b2)\n",
    "\n",
    "loss = -tf.reduce_mean(tf.reduce_sum((ts * tf.log(tf.clip_by_value(y, 1e-16, 1))), axis=1))\n",
    "train_way = tf.train.AdamOptimizer()\n",
    "train_step = train_way.minimize(loss)\n",
    "\n",
    "# tf.cast() 改變資料型態 np.astype change dtype\n",
    "acc = tf.cast(tf.equal(tf.argmax(y, axis=1), tf.argmax(ts, axis=1)), tf.float32)\n",
    "accuracy = tf.reduce_mean(acc, name='accuracy')\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer()) # 變數初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0  train:0.4667  test:0.2600  loss:1.3081\n",
      "100  train:0.8444  test:0.6500  loss:0.5786\n",
      "200  train:0.9789  test:0.9300  loss:0.2964\n",
      "300  train:0.9956  test:0.9600  loss:0.1755\n",
      "400  train:0.9989  test:0.9700  loss:0.1187\n",
      "500  train:0.9989  test:0.9700  loss:0.0842\n",
      "600  train:0.9989  test:0.9800  loss:0.0640\n",
      "700  train:1.0000  test:0.9500  loss:0.0494\n",
      "800  train:0.9989  test:0.9500  loss:0.0475\n",
      "900  train:1.0000  test:0.9200  loss:0.0341\n",
      "1000  train:1.0000  test:0.9100  loss:0.0322\n"
     ]
    }
   ],
   "source": [
    "data_num = x_train.shape[0]\n",
    "batch = 90\n",
    "lst = np.arange(data_num)\n",
    "feed_all = {xs: x_train, ts: t_train, keep_prob:1}\n",
    "for i_ in range(1001):\n",
    "    # 隨機打亂資料排序\n",
    "    np.random.shuffle(lst)\n",
    "    x_train = x_train[lst]\n",
    "    t_train = t_train[lst]\n",
    "   \n",
    "    for i in range(0, data_num, batch):  # 每 bench 100個資料\n",
    "        feed_data = {xs: x_train[i:i + batch], ts: t_train[i:i + batch], keep_prob:0.8}\n",
    "        sess.run(train_step, feed_dict=feed_data)\n",
    "    if i_ % 100 == 0:\n",
    "    # Accuracy test data\n",
    "        acc_test = sess.run(accuracy, feed_dict={xs: x_test, ts: t_test, keep_prob:1})\n",
    "        acc_train = sess.run(accuracy, feed_dict=feed_all)\n",
    "        los = sess.run(loss, feed_dict=feed_all)\n",
    "        print('%3d  train:%.4f  test:%.4f  loss:%.4f'%(i_, acc_train, acc_test, los))\n",
    "#sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train_data 可以完美fit 不意外  因為NN用的夠大\n",
    "### Test_data 竟然也有96% 表示二進位對FizzBuzz 也有點關係 XD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
